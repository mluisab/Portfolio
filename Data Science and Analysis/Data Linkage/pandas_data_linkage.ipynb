{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Maria Baba\"\n",
    "STUDENT_ID = \"14201089\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and data-linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pandas functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Basic Series Functionality\n",
    "Create a pandas `Series` with values `[1, 3, 5, np.nan, 6, 8]` and display basic functionality like `describe()`,` count()`, `sum()` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82fdeedf988907a74b17a01745454f7f",
     "grade": false,
     "grade_id": "cell-f561f052eef9823b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    3.0\n",
      "2    5.0\n",
      "3    NaN\n",
      "4    6.0\n",
      "5    8.0\n",
      "dtype: float64\n",
      "count    5.000000\n",
      "mean     4.600000\n",
      "std      2.701851\n",
      "min      1.000000\n",
      "25%      3.000000\n",
      "50%      5.000000\n",
      "75%      6.000000\n",
      "max      8.000000\n",
      "dtype: float64 5 23.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "# Your code here\n",
    "# series_1 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "values= ([1,3, 5, np.nan, 6, 8])\n",
    "series_1= pd.Series(values)\n",
    "print(series_1)\n",
    "\n",
    "d= series_1.describe()\n",
    "c= series_1.count()\n",
    "s= series_1.sum()\n",
    "print(d, c, s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d8e2a8c10b241193b84a96ce4e29c85",
     "grade": true,
     "grade_id": "cell-33d19898476ae3ea",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 1\n",
    "assert series_1.sum() == 23, \"Check your series values.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Series with Custom Index\n",
    "Create a `Series` with values `[30, 35, 40]` and indices `['Alice', 'Bob', 'Charlie']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e1dfa26d3f776267559933ec7bf04bf",
     "grade": false,
     "grade_id": "cell-5f1500ea9ce9c611",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice      30\n",
      "Bob        35\n",
      "Charlie    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "# Your code here\n",
    "# series_2 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "values_2= ([30, 35, 40])\n",
    "indices=['Alice', 'Bob', 'Charlie']\n",
    "series_2= pd.Series(values_2, index=indices)\n",
    "print (series_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b4b555dea6135aefc732106b18c654",
     "grade": true,
     "grade_id": "cell-9ac907bb27aa63c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 2\n",
    "assert 'Bob' in series_2, \"Ensure your series has the correct index.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Selection in Series\n",
    "Select and print the age of Bob from the `Series` created in Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08281416ca8307af160aabb77068b54a",
     "grade": false,
     "grade_id": "cell-b320f5e1176aa070",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "# Your code here\n",
    "age_bob = series_2.loc['Bob']\n",
    "print (age_bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce42ef76e372c78094be619f1eeeda19",
     "grade": true,
     "grade_id": "cell-7a162b3d00a7c9dd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 3\n",
    "assert age_bob == 35, \"Check the value you extracted for Bob's age.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Filtering Condition\n",
    "Filter and display elements in `series_2` that are greater than 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af45a89f19be20e3dd0812d7f5244e01",
     "grade": false,
     "grade_id": "cell-db9ac814f6206b45",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charlie    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Your code here\n",
    "filtered_series = series_2.loc[lambda x: (x >35)]\n",
    "print(filtered_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7a697bef555d3b21027b1ef9a492242",
     "grade": true,
     "grade_id": "cell-e1b0f3aabc7c001d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 4\n",
    "assert filtered_series['Charlie'] == 40, \"Check your filtering condition.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: Creating a DataFrame\n",
    "Create a DataFrame using the dictionary below and assign it to a variable named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "648e5c9e399f0e27526c3bc4092c45e7",
     "grade": false,
     "grade_id": "cell-6bf2866619f54dc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Charlie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>Diana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Name\n",
       "0   24    Alice\n",
       "1   27      Bob\n",
       "2   30  Charlie\n",
       "3   35    Diana"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\n",
    "    'Age': [24, 27, 30, 35],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana']\n",
    "}\n",
    "\n",
    "# Exercise 5\n",
    "# Your code here\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f98439b06cec695e27322d3724d58e",
     "grade": true,
     "grade_id": "cell-1df22909ff854e72",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 5\n",
    "assert 'Name' in df, \"Ensure your DataFrame contains the correct columns.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Retrieving the Index or Columns\n",
    "Retrieve and print the index and columns of the `DataFrame` created in Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e169e6f7cfbf540e5c9b82a587aa061",
     "grade": false,
     "grade_id": "cell-024f359d866c8a29",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n",
      "Index(['Age', 'Name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6\n",
    "# Your code here\n",
    "index_df = df.index\n",
    "print (index_df)\n",
    "columns_df = df.columns\n",
    "print(columns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91b1c1cedbc1dccd8669d2d4f17f83e6",
     "grade": true,
     "grade_id": "cell-00da66dca230f648",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 6\n",
    "assert len(index_df) == 4 and len(columns_df) == 2, \"Check your index and columns extraction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 7: Data Extraction with loc, iloc, and []\n",
    "Extract and print the `Age` of `Alice` using `loc`, `iloc`, and `[]` from the `DataFrame` created in Exercise 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1557f6ed3b7a265d2cfd7d323687da1",
     "grade": false,
     "grade_id": "cell-ca64155f67b2dc58",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age alice using loc: 24\n",
      "age alice using iloc: 24\n",
      "age alice using brackets: 24\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7\n",
    "# Your code here\n",
    "age_alice_loc = df.loc[0, 'Age']\n",
    "print('age alice using loc:',age_alice_loc)\n",
    "age_alice_iloc = df.iloc[0,0]\n",
    "print('age alice using iloc:',age_alice_iloc)\n",
    "age_alice_bracket= df[df['Name'] == 'Alice']['Age'].values[0]\n",
    "print('age alice using brackets:',age_alice_bracket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85c7c0018732a7123213c800843895ac",
     "grade": true,
     "grade_id": "cell-1d6147ef13c9d061",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Exercise 7\n",
    "assert age_alice_loc == 24 and age_alice_iloc == 24 and age_alice_bracket == 24, \"Check your data extraction methods.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Datasets\n",
    "\n",
    "Cool! Now that we have learned how pandas works, let's start using it with some data. \n",
    "\n",
    "### Exercise: Deterministic Data Linkage\n",
    "\n",
    "You will practice deterministic data linkage using synthetic datasets: `PatientDemo.csv` and `PatientVisits.csv`. Link these datasets using the `PatientID` field and perform analysis on the linked data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "import pandas as pd\n",
    "patient_df = pd.read_csv('PatientDemo.csv')\n",
    "visits_df = pd.read_csv('PatientVisits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the data that we have to see if we can find how to link both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ac525bf90e585de37987d81ab26c2f9",
     "grade": false,
     "grade_id": "cell-e5338aee544ec758",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Mccoy</td>\n",
       "      <td>1968-01-28</td>\n",
       "      <td>F</td>\n",
       "      <td>34536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>1942-02-11</td>\n",
       "      <td>F</td>\n",
       "      <td>73685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>1955-05-30</td>\n",
       "      <td>M</td>\n",
       "      <td>41751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1985-07-04</td>\n",
       "      <td>F</td>\n",
       "      <td>48590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>William</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>1948-07-01</td>\n",
       "      <td>F</td>\n",
       "      <td>74880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  FirstName LastName DateOfBirth Gender  ZipCode\n",
       "0          1      Megan    Mccoy  1968-01-28      F    34536\n",
       "1          2  Katherine    Bruce  1942-02-11      F    73685\n",
       "2          3     Robert  Sanchez  1955-05-30      M    41751\n",
       "3          4   Jonathan   Dennis  1985-07-04      F    48590\n",
       "4          5    William   Wilson  1948-07-01      F    74880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>VisitDate</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>TreatmentCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>D90</td>\n",
       "      <td>T36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>D29</td>\n",
       "      <td>T18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>D6</td>\n",
       "      <td>T31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>D74</td>\n",
       "      <td>T98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>D82</td>\n",
       "      <td>T62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitID  PatientID   VisitDate DiagnosisCode TreatmentCode\n",
       "0      101          1  2022-01-29           D90           T36\n",
       "1      102          2  2023-05-09           D29           T18\n",
       "2      103          3  2022-06-27            D6           T31\n",
       "3      104          4  2023-01-14           D74           T98\n",
       "4      105          5  2022-11-21           D82           T62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients:100\n",
      "Number of visits:100\n"
     ]
    }
   ],
   "source": [
    "display(patient_df.head())\n",
    "display(visits_df.head())\n",
    "\n",
    "number_of_patients = patient_df['PatientID'].count()\n",
    "print(f\"Number of patients:{number_of_patients}\")\n",
    "number_of_visits = visits_df['VisitID'].count()\n",
    "print(f\"Number of visits:{number_of_visits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be75019ed1533d01f9edfd48b7465181",
     "grade": true,
     "grade_id": "cell-e65882382c579a81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Linkage\n",
    "Perform deterministic data linkage by merging the `patient_df` and `visits_df` DataFrames using the `PatientID` field. Store the result in a new DataFrame called `merged_df`.\n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17c028842e63e22a5b57609e2f6b3cf5",
     "grade": false,
     "grade_id": "cell-fac7892bca5e74e7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>VisitID</th>\n",
       "      <th>VisitDate</th>\n",
       "      <th>DiagnosisCode</th>\n",
       "      <th>TreatmentCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Megan</td>\n",
       "      <td>Mccoy</td>\n",
       "      <td>1968-01-28</td>\n",
       "      <td>F</td>\n",
       "      <td>34536</td>\n",
       "      <td>101</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>D90</td>\n",
       "      <td>T36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>1942-02-11</td>\n",
       "      <td>F</td>\n",
       "      <td>73685</td>\n",
       "      <td>102</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>D29</td>\n",
       "      <td>T18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Robert</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>1955-05-30</td>\n",
       "      <td>M</td>\n",
       "      <td>41751</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>D6</td>\n",
       "      <td>T31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>1985-07-04</td>\n",
       "      <td>F</td>\n",
       "      <td>48590</td>\n",
       "      <td>104</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>D74</td>\n",
       "      <td>T98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>William</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>1948-07-01</td>\n",
       "      <td>F</td>\n",
       "      <td>74880</td>\n",
       "      <td>105</td>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>D82</td>\n",
       "      <td>T62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID  FirstName LastName DateOfBirth Gender  ZipCode  VisitID  \\\n",
       "0          1      Megan    Mccoy  1968-01-28      F    34536      101   \n",
       "1          2  Katherine    Bruce  1942-02-11      F    73685      102   \n",
       "2          3     Robert  Sanchez  1955-05-30      M    41751      103   \n",
       "3          4   Jonathan   Dennis  1985-07-04      F    48590      104   \n",
       "4          5    William   Wilson  1948-07-01      F    74880      105   \n",
       "\n",
       "    VisitDate DiagnosisCode TreatmentCode  \n",
       "0  2022-01-29           D90           T36  \n",
       "1  2023-05-09           D29           T18  \n",
       "2  2022-06-27            D6           T31  \n",
       "3  2023-01-14           D74           T98  \n",
       "4  2022-11-21           D82           T62  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = pd.merge (patient_df, visits_df, on=\"PatientID\")\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1. How many records are in the `merged_df` DataFrame?\n",
    "2. What is the average age of patients in `merged_df`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0540569141326e08acde1c919f0a4fe",
     "grade": false,
     "grade_id": "cell-ce9bb9e6c1a05c40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records is 100\n",
      "Average age of patients is 52.22\n"
     ]
    }
   ],
   "source": [
    "# Question 1: How many records are in the merged_df DataFrame?\n",
    "\n",
    "num_records = merged_df['PatientID'].count()\n",
    "print (f'Number of records is {num_records}')\n",
    "\n",
    "# Question 2: What is the average age of patients in merged_df?\n",
    "\n",
    "# Hint: You can use the datetime module to get the current year.\n",
    "from datetime import datetime\n",
    "current_year = datetime.now().year\n",
    "\n",
    "merged_df['DateOfBirth']= pd.to_datetime(merged_df['DateOfBirth'])\n",
    "ages= []\n",
    "for x in merged_df['DateOfBirth']:\n",
    "    year= int(x.year)\n",
    "    age= current_year-year\n",
    "    ages.append(age)\n",
    "average_age= np.mean(ages)\n",
    "print (f'Average age of patients is {average_age}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11f2cd1f93b97b7c02c392a073f4329a",
     "grade": true,
     "grade_id": "cell-4cb0b75dd98cd98c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Data Linkage\n",
    "\n",
    "Probabilistic data linkage is a technique used to bring together records from different datasets that do not share a unique identifier but have other fields in common. Unlike deterministic linkage, which requires exact matches on shared fields, probabilistic linkage considers the likelihood that two records refer to the same entity based on the similarity between these shared fields. This approach is particularly useful when working with data that may contain errors, variations, or inconsistencies in how information is recorded.\n",
    "\n",
    "## Challenges in Data Linkage\n",
    "\n",
    "- **Data Quality:** Datasets often have missing, misspelled, or inconsistently formatted data.\n",
    "- **Variability:** The same entity might be represented slightly differently in different datasets, due to typos, abbreviations, or variations in how data is entered.\n",
    "- **Absence of Unique Identifiers:** There might not be a unique, consistent identifier shared across datasets.\n",
    "\n",
    "## Approach\n",
    "\n",
    "Probabilistic linkage typically involves the following steps:\n",
    "\n",
    "1. **Selecting Variables:** Choosing which fields (or combinations of fields) will be used to link records between datasets.\n",
    "2. **Measuring Similarity:** Calculating a similarity score between records based on the selected variables.\n",
    "3. **Setting Thresholds:** Determining a similarity threshold above which records will be considered a match.\n",
    "\n",
    "Various similarity or distance metrics can be used in step 2, depending on the nature of the data and the specific requirements of the linkage task. One such metric, designed to handle some of the challenges mentioned above, is the Jaro-Winkler Distance, which you have seen in the lecture about data linkage.\n",
    "\n",
    "\n",
    "## Understanding Jaro-Winkler Distance\n",
    "\n",
    "The Jaro-Winkler Distance (JWD) is a measure of similarity between two strings. It is a variant of the Jaro distance metric and is mainly used in the area of record linkage. The Jaro-Winkler Distance metric is designed to capture similarity between two strings while accounting for possible errors such as typos and characters out of place.\n",
    "\n",
    "**Mathematical Definition**\n",
    "\n",
    "The Jaro-Winkler Distance between two strings $ s1 $ and $ s2 $ is calculated as follows:\n",
    "\n",
    "1. **Jaro Distance Calculation:**\n",
    "    - Let $ m $ be the number of matching characters between the two strings.\n",
    "    - Let $ t $ be the number of transpositions between the two strings.\n",
    "    - The Jaro distance $ d_j $ is then given by the formula:\n",
    "    $$\n",
    "    d_j = \\frac{1}{3} \\left( \\frac{m}{|s1|} + \\frac{m}{|s2|} + \\frac{m-t}{m} \\right)\n",
    "    $$\n",
    "    where $ |s1| $ and $ |s2| $ are the lengths of the strings $ s1 $ and $ s2 $ respectively.\n",
    "\n",
    "2. **Jaro-Winkler Distance Calculation:**\n",
    "    - Let $ l $ be the length of common prefix at the start of the string (maximum 4 characters).\n",
    "    - The Jaro-Winkler distance $ d_{jw} $ is then given by the formula:\n",
    "    $$\n",
    "    d_{jw} = d_j + l p (1 - d_j)\n",
    "    $$\n",
    "    where $ p $ is a constant scaling factor (usually set to $ 0.1 $).\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "- The Jaro-Winkler Distance ranges from $ 0 $ to $ 1 $, where $ 0 $ represents completely dissimilar strings and $ 1 $ represents identical strings.\n",
    "- The distance is symmetric, meaning $ d_{jw}(s1, s2) = d_{jw}(s2, s1) $.\n",
    "- It is particularly useful for short strings and for applications where the strings being compared have small length variations, making it widely used in record linkage tasks.\n",
    "- The Jaro-Winkler adjustment gives more favorable ratings to strings that match from the beginning, making it useful for cases where the position of characters in the string is important.\n",
    "\n",
    "**Example**\n",
    "\n",
    "For instance, the strings \"MARTHA\" and \"MARHTA\" have a Jaro distance of approximately $ 0.944 $ and a Jaro-Winkler Distance of approximately $ 0.961 $ with a prefix length of $ 3 $ and scaling factor $ p = 0.1 $.\n",
    "\n",
    "\n",
    "## Exercise: Implement distance\n",
    "\n",
    "Complete the function below by implementing the Jaro-Winkler Distance Calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac67b3285f1347fbc5ae0f441ab40341",
     "grade": false,
     "grade_id": "cell-32fed749c259b2fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def jaro_winkler_distance(s1: str, s2: str) -> float:\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "\n",
    "    m = 0  # Number of matching characters\n",
    "    t = 0  # Number of transpositions\n",
    "    l = min(len(s1), len(s2))  # Length of the shorter string\n",
    "\n",
    "    # Compute the number of matching characters and transpositions\n",
    "    for i in range(l):\n",
    "        if s1[i] == s2[i]:\n",
    "            m += 1\n",
    "        elif s1[i] != s2[i] and (i == 0 or (i > 0 and s1[i - 1] == s2[i - 1])):\n",
    "            t += 1\n",
    "\n",
    "    # Compute the Jaro distance\n",
    "    jaro = (1/3) * ((m / len(s1)) + (m / len(s2)) + ((m - t / 2) / m)) if m != 0 else 0.0\n",
    "    \n",
    "    # Compute the Jaro-Winkler distance\n",
    "    p = 0.1  # Scaling factor (constant)\n",
    "    l = 0  # Length of common prefix at the start of the string (max 4)\n",
    "    for i in range(min(len(s1), len(s2), 4)):\n",
    "        if s1[i] == s2[i]:\n",
    "            l += 1\n",
    "        else:\n",
    "            break\n",
    "    result= jaro + l*p*(1-jaro)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b06286b9435241befa6102327ad995a9",
     "grade": true,
     "grade_id": "cell-3583a3edc1c47026",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert jaro_winkler_distance('12', '1') == 0.85, 'Check your implementation.'\n",
    "assert jaro_winkler_distance(\"SAME\", \"SAME\") == 1.0, \\\n",
    "    f'Expected 1.0 for identical strings, but got {jaro_winkler_distance(\"SAME\", \"SAME\")}'\n",
    "assert jaro_winkler_distance(\"\", \"NOTSAME\") == 0.0, \\\n",
    "    f'Expected 0.0 for empty string comparison, but got {jaro_winkler_distance(\"\", \"NOTSAME\")}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Introduction\n",
    "\n",
    "In this exercise, we will work with two synthetic datasets: `EmploymentData.csv` and `SocialNetworkData.csv`. These datasets represent a common scenario in data linkage projects where we have information about individuals spread across different sources.\n",
    "\n",
    "## EmploymentData.csv\n",
    "\n",
    "The `EmploymentData.csv` dataset contains information about employees in various companies. Each record provides details about an employee's first name (`EmployeeFirstName`), last name (`EmployeeLastName`), the company they work for (`Company`), their position (`Position`), and their employment start date (`StartDate`).\n",
    "\n",
    "Here's a preview of the `EmploymentData.csv` structure:\n",
    "\n",
    "| EmployeeFirstName | EmployeeLastName | Company  | Position                | StartDate  |\n",
    "|-------------------|------------------|----------|-------------------------|------------|\n",
    "| John              | Doe              | ABC Corp | Data Scientist          | 2022-01-15 |\n",
    "| ...               | ...              | ...      | ...                     | ...        |\n",
    "\n",
    "## SocialNetworkData.csv\n",
    "\n",
    "The `SocialNetworkData.csv` dataset represents profiles from a professional social network. Each record includes the first name (`FirstName`), last name (`LastName`), current job title (`CurrentJobTitle`), the number of connections (`ConnectionsCount`), and the profile creation date (`ProfileCreationDate`).\n",
    "\n",
    "Here's a preview of the `SocialNetworkData.csv` structure:\n",
    "\n",
    "| FirstName | LastName | CurrentJobTitle       | ConnectionsCount | ProfileCreationDate |\n",
    "|-----------|----------|-----------------------|------------------|---------------------|\n",
    "| Jon       | Does     | Senior Data Scientist | 300              | 2018-06-05          |\n",
    "| ...       | ...      | ...                   | ...              | ...                 |\n",
    "\n",
    "## Objective\n",
    "\n",
    "Your task is to link records between these datasets probabilistically, based on the similarity of names using the Jaro-Winkler distance measure you will implement. Due to potential variations in how names are represented in each dataset (e.g., nicknames, typos), the linkage process requires careful consideration and application of string similarity measures.\n",
    "\n",
    "Load the `EmploymentData.csv` and `SocialNetworkData.csv` datasets into two separate DataFrames: `employment_df` and `network_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the employment data\n",
    "employment_df = pd.read_csv('EmploymentData.csv')\n",
    "\n",
    "# Load the social network data\n",
    "network_df = pd.read_csv('SocialNetworkData.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Data Linkage\n",
    "Use the `jaro_winkler_distance` function you implemented to link records between the `employment_df` and `network_df` DataFrames with the highest average similarity and a threshold of above 0.40. Store the result in a new DataFrame called `linked_df`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b74c2ffad07a1e6dc4e909af646c368d",
     "grade": false,
     "grade_id": "cell-77d2d30109393775",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.65\n",
    "linked_records = []\n",
    "\n",
    "for idx1, row1 in employment_df.iterrows():\n",
    "    highest_similarity = 0\n",
    "    best_match_index = -1\n",
    "    for idx2, row2 in network_df.iterrows():\n",
    "        first_name_similarity = jaro_winkler_distance(row1['EmployeeFirstName'], row2['FirstName'])\n",
    "        last_name_similarity = jaro_winkler_distance(row1['EmployeeLastName'], row2['LastName'])\n",
    "        average_similarity = (first_name_similarity + last_name_similarity) / 2\n",
    "        if average_similarity > highest_similarity:\n",
    "            data_row = row2\n",
    "            highest_similarity = average_similarity\n",
    "            best_match_index = idx2\n",
    "    if highest_similarity >= threshold:\n",
    "        linked_records.append(highest_similarity)\n",
    "        # Save the record pair if the similarity is above the threshold\n",
    "        # and add the similarity value to the record pair\n",
    "\n",
    "linked_df= pd.DataFrame(linked_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13480b04151fac7d7823a3f0df396ab8",
     "grade": true,
     "grade_id": "cell-d905cbbfeaa23aad",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  1.000000\n",
       "1  1.000000\n",
       "2  0.941667\n",
       "3  0.718750\n",
       "4  1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Data Linkage Results\n",
    "\n",
    "After performing data linkage, it's crucial to evaluate the quality of our matches. This step helps identify potential errors and assess the effectiveness of our linkage technique.\n",
    "\n",
    "To quantify the quality, we'll focus on two key metrics:\n",
    "- **Precision**: Measures the correctness of the matches. A higher precision means fewer false positives.\n",
    "- **Recall**: Measures the completeness of the matches. A higher recall means fewer true matches were missed.\n",
    "\n",
    "Precision and recall are defined as:\n",
    "$$ \\text{Precision} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Positives (FP)}} $$\n",
    "$$ \\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP) + False Negatives (FN)}} $$\n",
    "\n",
    "Using the ground truth (matches based on indices in this synthetic example), we can calculate these metrics to understand how well our linkage algorithm performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.73)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_matches(employment_df, network_df):\n",
    "    # Ground truth matches based on indices\n",
    "    ground_truth = set([(idx, idx) for idx in employment_df.index if idx in network_df.index])\n",
    "\n",
    "    # Matches made by the linkage algorithm\n",
    "    predicted_matches = set([(idx1, idx2) for idx1, row1 in employment_df.iterrows() \n",
    "                            for idx2, row2 in network_df.iterrows() \n",
    "                            if (row1['EmployeeFirstName'], row1['EmployeeLastName']) == \n",
    "                                (row2['FirstName'], row2['LastName'])])\n",
    "\n",
    "    # True Positives: Ground truth matches that are in the predicted matches\n",
    "    TP = len(ground_truth.intersection(predicted_matches))\n",
    "\n",
    "    # False Positives: Predicted matches that are not in the ground truth\n",
    "    FP = len(predicted_matches.difference(ground_truth))\n",
    "\n",
    "    # False Negatives: Ground truth matches that are not in the predicted matches\n",
    "    FN = len(ground_truth.difference(predicted_matches))\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "result= evaluate_matches(employment_df, network_df)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set threshold\n",
    "Now play around with the threshold and see how you could optimize the matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81bf63116e5be9bb354d0233e65743cc",
     "grade": false,
     "grade_id": "cell-9098da9f7c3003d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.98, 0.98)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_matches(employment_df, network_df):\n",
    "    # Ground truth matches based on indices\n",
    "    ground_truth = set([(idx, idx) for idx in employment_df.index if idx in network_df.index])\n",
    "\n",
    "    # Matches made by the linkage algorithm\n",
    "    predicted_matches = set()\n",
    "    threshold = 0.30\n",
    "\n",
    "    for idx1, row1 in employment_df.iterrows():\n",
    "        highest_similarity = 0\n",
    "        best_match_index = -1\n",
    "        for idx2, row2 in network_df.iterrows():\n",
    "            first_name_similarity = jaro_winkler_distance(row1['EmployeeFirstName'], row2['FirstName'])\n",
    "            last_name_similarity = jaro_winkler_distance(row1['EmployeeLastName'], row2['LastName'])\n",
    "            average_similarity = (first_name_similarity + last_name_similarity) / 2\n",
    "            if average_similarity > highest_similarity:\n",
    "                data_row = row2\n",
    "                highest_similarity = average_similarity\n",
    "                best_match_index = idx2\n",
    "        if highest_similarity >= threshold:\n",
    "            predicted_matches.add((idx1, best_match_index))\n",
    "    # True Positives: Ground truth matches that are in the predicted matches\n",
    "    TP = len(ground_truth.intersection(predicted_matches))\n",
    "\n",
    "    # False Positives: Predicted matches that are not in the ground truth\n",
    "    FP = len(predicted_matches.difference(ground_truth))\n",
    "\n",
    "    # False Negatives: Ground truth matches that are not in the predicted matches\n",
    "    FN = len(ground_truth.difference(predicted_matches))\n",
    "\n",
    "    # Calculate Precision and Recall\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    return precision, recall\n",
    "\n",
    "result= evaluate_matches(employment_df, network_df)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60daf24dee8569bdd625fb74a382b1c3",
     "grade": false,
     "grade_id": "cell-d5a79e1c0a1d2d61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conceptual Exercise: Data Linkage with Different Measurement Scales\n",
    "\n",
    "### Background\n",
    "Imagine you are working with two datasets collected from two different social surveys conducted in a city:\n",
    "\n",
    "1. **CityResidentSurvey.csv:**\n",
    "   - **Age:** Age of the resident.\n",
    "   - **Income:** Monthly income of the resident in USD.\n",
    "   - **EducationLevel:** Highest level of education attained (coded as 1: High School, 2: Bachelor’s, 3: Master’s, 4: Doctorate).\n",
    "   - **ResidentID:** A unique identifier for each resident in the survey.\n",
    "\n",
    "2. **NeighborhoodWellbeingSurvey.csv:**\n",
    "   - **Resident_Age:** Age of the resident, but with a ±2 years error margin due to the way it was collected.\n",
    "   - **Annual_Income:** Yearly income of the resident in USD.\n",
    "   - **Edu_Level:** Highest level of education attained, described with words (High School, Bachelor's Degree, Master's Degree, Doctorate).\n",
    "   - **WellbeingIndex:** A score representing the resident’s perceived wellbeing.\n",
    "   - **Resident_ID:** A unique identifier, but it does not match the ResidentID in the CityResidentSurvey.\n",
    "\n",
    "### Task\n",
    "You are tasked to link records between these two datasets. However, the data points are not measured exactly the same way in both datasets. Specifically:\n",
    "- Age is measured with a ±2 years error in the second dataset.\n",
    "- Income is reported monthly in the first dataset and annually in the second.\n",
    "- Education levels are coded numerically in the first dataset and described with words in the second.\n",
    "\n",
    "### Question\n",
    "Describe a step-by-step approach to link records between the two datasets as accurately as possible. Consider the differences in the measurement scales and potential errors in the data. How would you account for these differences to improve the accuracy of your linkage? You don't have to write any code, just explain your approach conceptually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa6a13db09f5c3003bb9745eac780117",
     "grade": true,
     "grade_id": "cell-8ba6fc8b8431eecc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE: First I would try to \"fix\" the way the data points are measured so they can be represented in the same way in both datasets. Looking at the Neighborhood Well Being survey, I would divide the income by 12 (number of months) to get a monthly income as in the other survey. Similarly, I would convert the level of education from strings to integers (or codes) as shown in the first survey, to make measurments similar. In terms of age, I would try to find an average between the ages showed in the first and second dataset, to get an approximate understanding of what the age can be.\n",
    "\n",
    "Then, I would link the datasets based on education as it would be the most accurate measurment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
